{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텐서플로우를 이용한 신경망 만들기 예제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기에서는 간단한 신경망을 구축하고 학습시킴으로써, MNIST라는 손글씨를 얼마만큼 정확하게 맞추는 지 확인해 보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 필요한 모듈들을 불러옵니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서플로우 라이브러리와 numpy 라이브러리, 그리고 matplotlib.pyplot을 불러 옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST란 손으로 쓴 0~9의 숫자 모음 데이터입니다. \n",
    "* 텐서플로우에는 예제로서 mnist가 포함되어 있습니다. \n",
    "* mnist 데이터를 다루기 편리하도록 몇가지 도구를 제공하므로 우리는 이를 활용하도록 하겠습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. MNIST 데이터를 다운로드합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input_data를 불러온 다음에, 이를 이용하여 mnist 데이터를 다운로드 받습니다. \n",
    "* one_hot을 True로 설정해 줍니다. \n",
    "* 예를 들어 one_hot 방식으로 3은 (0,0,0,1,0,0,0,0,0,0)로, 7은 (0,0,0,0,0,0,0,1,0,0)로 표현됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./data/mnist/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. MNIST 데이터 살펴보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST 데이터는 training data, validation data, test data로 구분되어 있으며 각각은 image와 label의 쌍으로 구성되어 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training data의 갯수는 55,000개입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000\n",
      "55000\n"
     ]
    }
   ],
   "source": [
    "print len(mnist.train.labels)\n",
    "print len(mnist.train.images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation data의 갯수는 5,000개, Test data의 갯수는 10,000개입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print mnist.validation.num_examples\n",
    "print mnist.test.num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One_hot 방식으로 불러온 mnist 일부를 보면 아래와 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.labels[0:5, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이를 일반적인 숫자로 변환하면 아래와 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, 0, 4])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.cls = np.argmax(mnist.test.labels, axis=1)\n",
    "mnist.test.cls[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 하이퍼 파라미터 설정해주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리는 입력 계층 --> 은닉 계층 1 --> 은닉 계층 2 --> 출력 계층으로 구성된 신경망을 구축할 것입니다. 각 계층에서의 노드의 갯수는 아래와 같이 설정하도록 하겠습니다.\n",
    "* 입력 계층의 노드 수 : 784\n",
    "* 은닉 계층1의 노드 수 : 256\n",
    "* 은닉 계층2의 노드 수 : 256\n",
    "* 출력 계층의 노드 수 : 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 입력 계층 : MNIST 이미지 각각은 28x28의 해상도를 가지고 있기 때문에 입력 계층의 노드수는 784가 됩니다.\n",
    "* 출력 계층 : 0부터 9까지 총 10개의 클래스로 구성 (One_hot) 되기 때문에 출력 계층의 노드 수는 10이 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_node_input = 28*28\n",
    "num_node_hidden1 = 256\n",
    "num_node_hidden2 = 256\n",
    "num_node_output = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 모델 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "입력 계층을 플레이스홀더로 정의해 줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_true = tf.placeholder(tf.float32, [None, num_node_input])\n",
    "y_true = tf.placeholder(tf.float32, [None, num_node_output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "은닉 계층 1의 가중치와 편향을 설정해 줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight_1 = tf.Variable(tf.truncated_normal([num_node_input, num_node_hidden1], stddev=0.01))\n",
    "bias_1 = tf.Variable(tf.zeros([num_node_hidden1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "은닉 계층 2의 가중치와 편향을 설정해 줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight_2 = tf.Variable(tf.truncated_normal([num_node_hidden1, num_node_hidden2], stddev=0.01))\n",
    "bias_2 = tf.Variable(tf.zeros([num_node_hidden2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "출닉 계층의 가중치와 편향을 설정해 줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight_3 = tf.Variable(tf.truncated_normal([num_node_hidden2, num_node_output], stddev=0.01))\n",
    "bias_3 = tf.Variable(tf.zeros([num_node_output]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "은닉 계층 1, 은닉 계층 2, 출력 계층에서 연산을 수행하고 relu를 이용해 non-linearity를 주게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_1 = tf.nn.relu(tf.add(tf.matmul(x_true, weight_1), bias_1))\n",
    "hidden_2 = tf.nn.relu(tf.add(tf.matmul(hidden_1, weight_2), bias_2))\n",
    "y_pred = tf.nn.relu(tf.add(tf.matmul(hidden_2, weight_3), bias_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예측 값과 실제 값의 차를 이용해 cross entropy를 구해 주고 이를 평균한 값이 비용이 됩니다. 비용을 최소화하도록 학습시켜 주기 위해 optimizer를 정의해 줍니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_pred, labels=y_true))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 학습시키기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "세션을 실행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST의 training data는 55,000개나 되기 때문에 batch로 묶어 주어 피드해 주게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "total_batch = int(mnist.train.num_examples/batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습을 시작합니다. \n",
    "* 앞에서 정의한 num_epochs 만큼 학습을 진행합니다.\n",
    "* batch로 100개씩 묶어서 피드하게 됩니다.\n",
    "* 텐서플로우에서는 mnist 데이터의 피드를 편하게 하기 위해 next_batch()라는 함수를 제공합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : {0001} Cost : 1.914\n",
      "Epoch : {0002} Cost : 1.873\n",
      "Epoch : {0003} Cost : 1.867\n",
      "Epoch : {0004} Cost : 1.828\n",
      "Epoch : {0005} Cost : 1.610\n",
      "Epoch : {0006} Cost : 1.409\n",
      "Epoch : {0007} Cost : 1.396\n",
      "Epoch : {0008} Cost : 1.392\n",
      "Epoch : {0009} Cost : 1.386\n",
      "Epoch : {0010} Cost : 1.386\n",
      "Epoch : {0011} Cost : 1.381\n",
      "Epoch : {0012} Cost : 1.378\n",
      "Epoch : {0013} Cost : 1.378\n",
      "Epoch : {0014} Cost : 1.377\n",
      "Epoch : {0015} Cost : 1.378\n",
      "Epoch : {0016} Cost : 1.375\n",
      "Epoch : {0017} Cost : 1.374\n",
      "Epoch : {0018} Cost : 1.373\n",
      "Epoch : {0019} Cost : 1.373\n",
      "Epoch : {0020} Cost : 1.372\n",
      "Epoch : {0021} Cost : 1.370\n",
      "Epoch : {0022} Cost : 1.370\n",
      "Epoch : {0023} Cost : 1.369\n",
      "Epoch : {0024} Cost : 1.370\n",
      "Epoch : {0025} Cost : 1.370\n",
      "Epoch : {0026} Cost : 1.367\n",
      "Epoch : {0027} Cost : 1.369\n",
      "Epoch : {0028} Cost : 1.371\n",
      "Epoch : {0029} Cost : 1.367\n",
      "Epoch : {0030} Cost : 1.367\n",
      "최적화가 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    total_cost = 0\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        sess.run(optimizer, {x_true:batch_xs, y_true:batch_ys})\n",
    "        total_cost += sess.run(cost, {x_true:batch_xs, y_true:batch_ys})\n",
    "    \n",
    "    print \"Epoch : {%04d}\" % (epoch + 1), \"Cost : {:.3f}\".format(total_cost / total_batch)\n",
    "    \n",
    "print \"최적화가 완료되었습니다.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 평가하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 예측 값과 실제 값이 동일한 경우를 카운트해 줍니다. \n",
    "* 이를 실수로 캐스팅한 다음에 평균을 냄으로써 정확도를 정의합니다. \n",
    "* 세션을 수행하여 테스트 이미지와 레이블을 전달하여 정확도를 구할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.4986\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y_pred,1), tf.argmax(y_true,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print \"정확도 :\", sess.run(accuracy, {x_true: mnist.test.images,\n",
    "                                     y_true: mnist.test.labels})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
